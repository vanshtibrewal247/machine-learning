{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a440d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary=pd.read_csv(\"C:/Users/VANSH TIBREWAL/Downloads/archive (3)/Experience-Salary.csv\")\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=salary[['exp(in months)']]\n",
    "y=salary['salary(in thousands)']\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Feature scaling (IMPORTANT)\n",
    "# -----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "X_test_scaled = scaler.transform(X_test_raw)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Add bias column\n",
    "# -----------------------------\n",
    "# X_train = np.column_stack((np.ones(len(X_train_scaled)), X_train_scaled))\n",
    "# X_test = np.column_stack((np.ones(len(X_test_scaled)), X_test_scaled))\n",
    "X_train = np.insert(\n",
    "    X_train_scaled,\n",
    "    0,\n",
    "    1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_test = np.insert(\n",
    "\n",
    "    X_test_scaled,\n",
    "    0,\n",
    "    1,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Gradient Descent function\n",
    "# -----------------------------\n",
    "def gradient_descent(X, y, theta, alpha, epochs):\n",
    "    m = len(y)\n",
    "    loss_history = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        \n",
    "        \n",
    "        predictions = X.dot(theta)\n",
    "    #    print(predictions.shape)\n",
    "        errors = predictions - y\n",
    "\n",
    "\n",
    "        theta0_partial = (2/m) * np.sum(errors)\n",
    "        theta1_partial = (2/m) * errors.dot(X[:, 1])\n",
    "      #  print(errors.shape)\n",
    "        theta[0] -= alpha * theta0_partial\n",
    "        theta[1] -= alpha * theta1_partial\n",
    "        \n",
    "        loss = (1/m) * np.sum(errors ** 2)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    return theta, loss_history\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Train model\n",
    "# -----------------------------\n",
    "theta = np.array([0.0, 0.0])\n",
    "alpha = 0.05\n",
    "epochs = 1000\n",
    "\n",
    "theta, loss_history = gradient_descent(\n",
    "    X_train, y_train, theta, alpha, epochs\n",
    ")\n",
    "\n",
    "print(\"Learned parameters:\")\n",
    "print(\"theta0 (intercept):\", theta[0])\n",
    "print(\"theta1 (slope):\", theta[1])\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Predictions on test set\n",
    "# -----------------------------\n",
    "y_pred_test = X_test.dot(theta)\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Plot regression line (TRAIN)\n",
    "# -----------------------------\n",
    "idx = np.argsort(X_train_scaled[:, 0])\n",
    "plt.figure()\n",
    "plt.scatter(X_train_scaled, y_train)\n",
    "plt.plot(\n",
    "    X_train_scaled[idx],\n",
    "    X_train[idx].dot(theta),\n",
    "    color='red'\n",
    ")\n",
    "plt.xlabel(\"Experience (scaled)\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.title(\"Linear Regression (Train Data)\")\n",
    "plt.show()\n",
    "# plt.figure()\n",
    "# plt.scatter(X_train_scaled, y_train)\n",
    "# plt.plot(\n",
    "#     np.sort(X_train_scaled),\n",
    "#     X_train[np.argsort(X_train_scaled)].dot(theta)\n",
    "#     ,c='red'\n",
    "# )\n",
    "# plt.xlabel(\"Median Income (scaled)\")\n",
    "# plt.ylabel(\"House Value\")\n",
    "# plt.title(\"Linear Regression (Train Data)\")\n",
    "# plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Plot loss vs epochs\n",
    "# -----------------------------\n",
    "plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training Loss vs Epochs\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Predicted vs Actual (TEST)\n",
    "# -----------------------------\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred_test)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs Predicted (Test Data)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(X_train_scaled)\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a523e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17261fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
